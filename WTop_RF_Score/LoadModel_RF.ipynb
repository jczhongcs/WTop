{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d232f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "import  numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xlrd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import openpyxl\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFE\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import queue\n",
    "import warnings\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "%run myfun.ipynb\n",
    "import os\n",
    "import glob\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "clf = joblib.load(\"D:\\\\RFModel\\\\rf_model.m\")\n",
    "selector = joblib.load('D:\\\\RFModel\\\\rf_model_selector.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4337b7a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and preprocessing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading CSV: 100%|███████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 12.18it/s]\n",
      "[Parallel(n_jobs=30)]: Using backend ThreadingBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done 140 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying feature selection and predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done 390 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=30)]: Done 740 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=30)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "Predicting scores: 100%|███████████████████████████████████████████████████████| 12502/12502 [00:02<00:00, 4675.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completed and results saved.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "feature_start = 10\n",
    "feature_num = 50\n",
    "\n",
    "result_path = r\"\\Fraction_11\"\n",
    "path_directory = os.path.dirname(result_path)\n",
    "path = os.path.join(path_directory, \"out_all_prsm.csv\")\n",
    "\n",
    "\n",
    "model_path = 'random_forest_model.pkl'\n",
    "selector_path = 'selector.pkl'\n",
    "\n",
    "\n",
    "def read_single_csv(input_path):\n",
    "    total_rows = sum(1 for _ in open(input_path, encoding='utf-8')) - 1\n",
    "    chunks = pd.read_csv(input_path, chunksize=10000)\n",
    "    df_list = []\n",
    "    for chunk in tqdm(chunks, total=total_rows // 10000 + 1, desc=\"Reading CSV\"):\n",
    "        df_list.append(chunk)\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "print(\"Reading and preprocessing data...\")\n",
    "data = read_single_csv(path)\n",
    "\n",
    "\n",
    "mean_fill_cols = ['feature21', 'feature22', 'feature23']\n",
    "data[mean_fill_cols] = data[mean_fill_cols].fillna(data[mean_fill_cols].mean())\n",
    "\n",
    "data[['feature46', 'feature47', 'feature48']] = data[['feature46', 'feature47', 'feature48']].fillna(0)\n",
    "data['feature48'] = data['feature48'].replace([np.inf, -np.inf], 0)\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Applying feature selection and predicting...\")\n",
    "raw_data = data.copy()\n",
    "\n",
    "\n",
    "numerical_features = data.iloc[:, feature_start:feature_start + feature_num].astype(float)\n",
    "\n",
    "\n",
    "test_feature_selected = selector.transform(numerical_features.astype(float))\n",
    "\n",
    "\n",
    "probabilities = clf.predict_proba(test_feature_selected)\n",
    "class_1_probs = probabilities[:, 1]\n",
    "raw_data['score'] = class_1_probs\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(data)), desc=\"Predicting scores\"):\n",
    "    raw_data['score'].iloc[i] = class_1_probs[i]\n",
    "\n",
    "\n",
    "raw_data.sort_values(by=[raw_data.columns[0], 'score', raw_data.columns[9]], ascending=[True, False, False], inplace=True)\n",
    "raw_data.to_csv(result_path + '_candi_output.csv', index=False)\n",
    "\n",
    "\n",
    "grouped_best = (\n",
    "    raw_data.sort_values(by=['score', 'match fragment'], ascending=[False, False])\n",
    "            .groupby(raw_data.columns[0], as_index=False)\n",
    "            .first()\n",
    ")\n",
    "\n",
    "\n",
    "grouped_best.sort_values(by=['score', grouped_best.columns[9]], ascending=[False, False], inplace=True)\n",
    "grouped_best.to_csv(result_path + '_output.csv', index=False)\n",
    "\n",
    "print(\"Prediction completed and results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe1bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fill_cols = ['feature21', 'feature22', 'feature23']\n",
    "data[mean_fill_cols] = data[mean_fill_cols].fillna(data[mean_fill_cols].mean())\n",
    "\n",
    "data[['feature46', 'feature47', 'feature48']] = data[['feature46', 'feature47', 'feature48']].fillna(0)\n",
    "data['feature48'] = data['feature48'].replace([np.inf, -np.inf], 0)\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "raw_data = data.copy()\n",
    "\n",
    "numerical_features = data.iloc[:, feature_start:feature_start + feature_num].astype(float)\n",
    "\n",
    "test_feature_selected = selector.transform(numerical_features.astype(float))\n",
    "\n",
    "probabilities = clf.predict_proba(test_feature_selected)\n",
    "class_1_probs = probabilities[:, 1]\n",
    "raw_data['score'] = class_1_probs\n",
    "\n",
    "raw_data.sort_values(by=[raw_data.columns[0], 'score', raw_data.columns[9]], ascending=[True, False, False], inplace=True)\n",
    "raw_data.to_csv(result_path + '_candi_output.csv', index=False)\n",
    "\n",
    "\n",
    "grouped_best = (\n",
    "    raw_data.sort_values(by=['score', 'match fragment'], ascending=[False, False])\n",
    "            .groupby(raw_data.columns[0], as_index=False)\n",
    "            .first()\n",
    ")\n",
    "\n",
    "\n",
    "grouped_best.sort_values(by=['score', grouped_best.columns[9]], ascending=[False, False], inplace=True)\n",
    "grouped_best.to_csv(result_path + '_output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b2a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
